{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6861ab3-dffd-4da4-a819-b090b8ae756e",
   "metadata": {},
   "source": [
    "### Load chunks as we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b54c46a-e478-46ea-9828-1505c9cfef26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:54:37.180356Z",
     "iopub.status.busy": "2025-09-04T14:54:37.180128Z",
     "iopub.status.idle": "2025-09-04T14:54:38.744294Z",
     "shell.execute_reply": "2025-09-04T14:54:38.743491Z",
     "shell.execute_reply.started": "2025-09-04T14:54:37.180335Z"
    }
   },
   "outputs": [],
   "source": [
    "from chonkie import SemanticChunker\n",
    "from pathlib import Path\n",
    "\n",
    "md_filepath = Path(\"data/parsed/hai_ai-index-report-2025_chapter2_excerpts-parsed-w-imgs.md\")\n",
    "md_txt = md_filepath.read_text()\n",
    "\n",
    "chunker = SemanticChunker(\n",
    "    embedding_model=\"minishlab/potion-base-8M\",  # Default model\n",
    "    threshold=0.5,                               # Similarity threshold (0-1) or (1-100) or \"auto\"\n",
    "    chunk_size=2048,                              # Maximum tokens per chunk\n",
    "    min_sentences=1                              # Initial sentences per chunk\n",
    ")\n",
    "chunk_texts = chunker.chunk(md_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a2a8a4",
   "metadata": {},
   "source": [
    "### Set up Weaviate Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22af250e-be00-421a-948c-3daeda7e3b19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:54:56.451880Z",
     "iopub.status.busy": "2025-09-04T14:54:56.451569Z",
     "iopub.status.idle": "2025-09-04T14:54:57.365177Z",
     "shell.execute_reply": "2025-09-04T14:54:57.364283Z",
     "shell.execute_reply.started": "2025-09-04T14:54:56.451856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "%store -r WEAVIATE_IP\n",
    "%store -r AWS_ACCESS_KEY\n",
    "%store -r AWS_SECRET_KEY\n",
    "%store -r AWS_SESSION_TOKEN\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    WEAVIATE_IP,\n",
    "    headers = {\n",
    "        \"X-AWS-Access-Key\": AWS_ACCESS_KEY,\n",
    "        \"X-AWS-Secret-Key\": AWS_SECRET_KEY,\n",
    "        \"X-AWS-Session-Token\": AWS_SESSION_TOKEN,\n",
    "    }        \n",
    ")\n",
    "\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842550b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:54:58.830340Z",
     "iopub.status.busy": "2025-09-04T14:54:58.829973Z",
     "iopub.status.idle": "2025-09-04T14:54:58.838807Z",
     "shell.execute_reply": "2025-09-04T14:54:58.838084Z",
     "shell.execute_reply.started": "2025-09-04T14:54:58.830320Z"
    }
   },
   "outputs": [],
   "source": [
    "client.collections.delete(\"Chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e202bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:54:59.585059Z",
     "iopub.status.busy": "2025-09-04T14:54:59.584658Z",
     "iopub.status.idle": "2025-09-04T14:54:59.751203Z",
     "shell.execute_reply": "2025-09-04T14:54:59.750426Z",
     "shell.execute_reply.started": "2025-09-04T14:54:59.585033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x7f2d301e74a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weaviate.classes.config import Property, DataType, Configure, Tokenization\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"Chunks\",\n",
    "    properties=[\n",
    "        Property(\n",
    "            name=\"document_title\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"chunk\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"chunk_number\",\n",
    "            data_type=DataType.INT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"filename\",\n",
    "            data_type=DataType.TEXT,\n",
    "            tokenization=Tokenization.FIELD\n",
    "        ),\n",
    "    ],\n",
    "    vector_config=[\n",
    "        Configure.Vectors.text2vec_aws(\n",
    "            name=\"default\",\n",
    "            source_properties=[\"document_title\", \"chunk\"],\n",
    "            region=\"us-west-2\",\n",
    "            service=\"bedrock\",\n",
    "            model=\"amazon.titan-embed-text-v2:0\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9e2f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:55:08.608523Z",
     "iopub.status.busy": "2025-09-04T14:55:08.608234Z",
     "iopub.status.idle": "2025-09-04T14:55:08.612165Z",
     "shell.execute_reply": "2025-09-04T14:55:08.611136Z",
     "shell.execute_reply.started": "2025-09-04T14:55:08.608501Z"
    }
   },
   "outputs": [],
   "source": [
    "chunks = client.collections.use(\"Chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34f3bad",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee53991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:55:09.935945Z",
     "iopub.status.busy": "2025-09-04T14:55:09.935644Z",
     "iopub.status.idle": "2025-09-04T14:55:11.759350Z",
     "shell.execute_reply": "2025-09-04T14:55:11.758312Z",
     "shell.execute_reply.started": "2025-09-04T14:55:09.935924Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:00, 21657.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with chunks.batch.fixed_size(batch_size=100) as batch:\n",
    "    for i, chunk_text in tqdm(enumerate(chunk_texts)):\n",
    "        obj = {\n",
    "            \"document_title\": \"HAI AI Index Report 2025\",\n",
    "            \"filename\": \"data/pdfs/hai_ai-index-report-2025_chapter2_excerpts.pdf\",\n",
    "            \"chunk\": chunk_text.text,\n",
    "            \"chunk_number\": i + 1,\n",
    "        }\n",
    "\n",
    "        # Add object to batch for import with (batch.add_object())\n",
    "        # BEGIN_SOLUTION\n",
    "        batch.add_object(\n",
    "            properties=obj\n",
    "        )\n",
    "        # END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed8bc9",
   "metadata": {},
   "source": [
    "### RAG queries\n",
    "\n",
    "How do we perform RAG in this scenario? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3e0fed",
   "metadata": {},
   "source": [
    "This is a bit different, because we haven't embedded the images (or stored them in Weaviate).\n",
    "\n",
    "In this scenario, let's:\n",
    "\n",
    "- Retrieve text chunks\n",
    "- Get images referred to in the text\n",
    "- Convert the images to base64\n",
    "- Send (retrieved text + images + prompt) to LLM for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cae8dd66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T15:08:47.467155Z",
     "iopub.status.busy": "2025-09-04T15:08:47.466849Z",
     "iopub.status.idle": "2025-09-04T15:08:47.566599Z",
     "shell.execute_reply": "2025-09-04T15:08:47.565752Z",
     "shell.execute_reply.started": "2025-09-04T15:08:47.467133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "\n",
      "Source: Wijk et al., 2024 | Chart: 2025 AI Index report\n",
      "\n",
      "![Image](data/parsed/hai_ai-index-report-2025_chapter2_excerpts-parsed-w-imgs_artifacts/image_000012_90c7c87f35758c0ce8c4a95f97089830098242f6ae4df85ab58cd0aa4f31fa8b.png)\n",
      "\n",
      "## Chapter 2: Technical Performance\n",
      "\n",
      "## Self-Driving Cars\n",
      "\n",
      "Self-driving vehicles have long been a goal for AI researchers and technologists. However, their widespread adoption has been  slower  than  anticipated.  Despite  many  predictions that  fully  autonomous  driving  is  imminent,  widespread  use of  self-driving  vehicles  has yet  to  become  a  reality.  Still,  in recent  years,  signi fi cant  progress  has  been  made.  In  cities like  San  Francisco  and  Phoenix, fl eets  of  self-driving  taxis are  now  operating  commercially.  This  section  examines recent advancements in autonomous driving, focusing on deployment, technological breakthroughs and new benchmarks, safety performance, and policy challenges.\n",
      "\n",
      "## Deployment\n",
      "\n",
      "Self-driving cars ...\n",
      "\n",
      "========================================\n",
      "\n",
      "2.9 Robotics and Automous Motion\n",
      "\n",
      "## Technical Innovations and New Benchmarks\n",
      "\n",
      "Over  the  past  year,  self-driving  technology  has  advanced signi fi cantly,  both  in  vehicle  capabilities  and  benchmarking methods.  In  October  2024,  Tesla  unveiled  the  Cybercab,  a two-passenger autonomous vehicle without a steering wheel or  pedals,  which  is  set  for  production  in  2026  at  a  price  of under  $30,000. Tesla  also  unveiled  the  Robovan,  an  electric autonomous van designed to transport up to 20 passengers. Meanwhile, Baidu's Apollo Go launched its latest-generation robotaxi, the RT6, across multiple cities in China (Figure 2.9.12). With a price tag of just $30,000 and a battery-swapping system, the  RT6  represents  a  major  step  toward  making  self-driving technology more cost-e ff ective and scalable. As costs continue to decline, the adoption of autonomous vehicles is expected to accelerate. Notable business partnerships have also advanced self-driving  tech...\n",
      "\n",
      "========================================\n",
      "\n",
      "Figure 2.9.11\n",
      "\n",
      "China's  self-driving  revolution  is  also  accelerating,  led  by companies like Baidu's Apollo Go, which reported 988,000 rides across China in Q3 2024, re fl ecting a 20% year-over-year increase. In October 2024, the company was operating 400 robotaxis and announced plans to expand its fl eet to 1,000 by the end of 2025. Pony.AI, another Chinese autonomous vehicle manufacturer, has pledged to scale its robotaxi fl eet from 200 to at least 1,000 vehicles-with expectations that the fl eet will reach 2,000 to 3,000 by the end of 2026. China is leading the way in autonomous vehicle testing, with reports indicating  that  it  is  testing  more  driverless  cars  than  any other country and currently rolling them out across 16 cities. Robotaxis  in  China  are  notably  a ff ordable-even  cheaper, in  some  cases,  than  rides  provided  by  human  drivers.  To support  this growth, China  has prioritized establishing national regulations to govern the deployment of drive...\n"
     ]
    }
   ],
   "source": [
    "response = chunks.query.hybrid(\n",
    "    query=\"Latest in self-driving cars\",\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(f\"\\n\" + \"=\" * 40)\n",
    "    print(o.properties[\"chunk\"][:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a729583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T15:08:53.000538Z",
     "iopub.status.busy": "2025-09-04T15:08:53.000268Z",
     "iopub.status.idle": "2025-09-04T15:08:53.004230Z",
     "shell.execute_reply": "2025-09-04T15:08:53.003261Z",
     "shell.execute_reply.started": "2025-09-04T15:08:53.000519Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_image_paths(text):\n",
    "    \"\"\"Extract image paths from markdown-style image references.\"\"\"\n",
    "    pattern = r'!\\[.*?\\]\\((.*?)\\)'\n",
    "    return re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d036efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T15:08:53.626222Z",
     "iopub.status.busy": "2025-09-04T15:08:53.625903Z",
     "iopub.status.idle": "2025-09-04T15:08:53.630246Z",
     "shell.execute_reply": "2025-09-04T15:08:53.629582Z",
     "shell.execute_reply.started": "2025-09-04T15:08:53.626201Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_image_base64s(image_paths, base_path=None):\n",
    "    import base64\n",
    "    base64_images = []\n",
    "    for img_path in image_paths:\n",
    "        full_path = Path(base_path) / img_path if base_path else Path(img_path)\n",
    "        image_bytes = full_path.read_bytes()\n",
    "        base64_string = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "        base64_images.append(base64_string)\n",
    "\n",
    "    return base64_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "430397bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T15:08:54.087250Z",
     "iopub.status.busy": "2025-09-04T15:08:54.086960Z",
     "iopub.status.idle": "2025-09-04T15:08:54.092895Z",
     "shell.execute_reply": "2025-09-04T15:08:54.091889Z",
     "shell.execute_reply.started": "2025-09-04T15:08:54.087229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding image paths: ['data/parsed/hai_ai-index-report-2025_chapter2_excerpts-parsed-w-imgs_artifacts/image_000012_90c7c87f35758c0ce8c4a95f97089830098242f6ae4df85ab58cd0aa4f31fa8b.png']\n",
      "Adding image paths: []\n",
      "Adding image paths: []\n"
     ]
    }
   ],
   "source": [
    "all_chunks = \"\"\n",
    "all_images = []\n",
    "\n",
    "for o in response.objects:\n",
    "    chunk_text = o.properties[\"chunk\"]\n",
    "    image_paths = extract_image_paths(chunk_text)\n",
    "    print(f\"Adding image paths: {image_paths}\")\n",
    "    all_images.extend(get_image_base64s(image_paths, base_path=\"data/parsed\"))\n",
    "\n",
    "    all_chunks += \"\\n\\n\" + chunk_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d93da885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T15:08:59.811749Z",
     "iopub.status.busy": "2025-09-04T15:08:59.811477Z",
     "iopub.status.idle": "2025-09-04T15:08:59.815651Z",
     "shell.execute_reply": "2025-09-04T15:08:59.814963Z",
     "shell.execute_reply.started": "2025-09-04T15:08:59.811728Z"
    }
   },
   "outputs": [],
   "source": [
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": []\n",
    "    }\n",
    "]\n",
    "\n",
    "for img in all_images:\n",
    "    content = {\n",
    "        \"image\": {\n",
    "            \"format\": \"png\",\n",
    "            \"source\": {\n",
    "                \"bytes\": img\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    # Append `content`` to message[\"content\"]\n",
    "    # BEGIN_SOLUTION\n",
    "    message[\"content\"].append(content)\n",
    "    # END_SOLUTION\n",
    "    \n",
    "task_text = \"\"\"\n",
    "What does this tell us about the latest in self-driving cars\n",
    "\n",
    "Describe the details from the figures as well, if necessary.\n",
    "\"\"\" + \"\\n\\n\" + all_chunks    \n",
    "message[\"content\"].append({\"text\": task_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3b0c9d7-352c-4ea9-ba2a-8e0eac890adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T15:13:18.143754Z",
     "iopub.status.busy": "2025-09-04T15:13:18.143467Z",
     "iopub.status.idle": "2025-09-04T15:13:22.269508Z",
     "shell.execute_reply": "2025-09-04T15:13:22.268215Z",
     "shell.execute_reply.started": "2025-09-04T15:13:18.143734Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/botocore/auth.py:425: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  datetime_now = datetime.datetime.utcnow()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Response Content Text]\n",
      "\n",
      "\n",
      "## Text\n",
      "\n",
      "The following is a list of the top 10 most common types of malware:\n",
      "\n",
      "1. **Adware**: This type of malware displays unwanted advertisements on a user's device. It often comes bundled with free software and can significantly slow down the device.\n",
      "2. **Browser Hijackers**: These malware programs modify a user's browser settings without their consent, redirecting them to unwanted websites or changing their homepage.\n",
      "3. **Ransomware**: This malicious software encrypts a user's files and demands payment (usually in cryptocurrency) to decrypt them. It can cause significant data loss if the ransom is not paid.\n",
      "4. **Trojans**: These are disguised as legitimate software but, once executed, perform malicious actions such as stealing data or installing additional malware.\n",
      "5. **Worms**: These self-replicating malware programs spread across networks without user intervention. They can consume network resources and cause significant damage.\n",
      "6. **Spyware**: This type of malware secretly monitors a user's activities and collects sensitive information, which is then sent to a third party.\n",
      "7. **Keyloggers**: These malware programs record every keystroke a user makes, capturing sensitive information such as passwords and credit card numbers.\n",
      "8. **Rootkits**: These are designed to hide the existence of certain programs or processes from normal detection methods. They can be used to gain unauthorized access to a system.\n",
      "9. **Fileless Malware**: This type of malware operates within a\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "client = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=\"us-west-2\",\n",
    ")\n",
    "\n",
    "# MODEL_ID = \"us.amazon.nova-lite-v1:0\"\n",
    "MODEL_ID = \"us.amazon.nova-pro-v1:0\"\n",
    "# Define your system prompt(s).\n",
    "system_list = [    {\n",
    "        \"text\": \"You are an expert. Read the provided text and content of these images and answer the questions thoughtfully but succinctly if possible.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"maxTokens\": 300, \"topP\": 0.1, \"topK\": 20, \"temperature\": 0.3}\n",
    "\n",
    "native_request = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "# Invoke the model and extract the response body.\n",
    "response = client.invoke_model(modelId=MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee4c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "anthropic_response = anthropic.Anthropic().messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    # Add [message] as the messages to pass to Claude\n",
    "    # BEGIN_SOLUTION\n",
    "    messages=[message]\n",
    "    # END_SOLUTION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f2923",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anthropic_response.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67fd35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
